{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Using cached numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Using cached soxr-0.3.7-cp312-cp312-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (4.11.0)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Using cached msgpack-1.0.8-cp312-cp312-win_amd64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa)\n",
      "  Using cached cffi-1.16.0-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached msgpack-1.0.8-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Downloading numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/2.7 MB 825.8 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.3/2.7 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.0/2.7 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 7.5 MB/s eta 0:00:00\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Using cached soxr-0.3.7-cp312-cp312-win_amd64.whl (184 kB)\n",
      "Using cached cffi-1.16.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: soxr, pycparser, msgpack, llvmlite, lazy-loader, audioread, pooch, numba, cffi, soundfile, librosa\n",
      "Successfully installed audioread-3.0.1 cffi-1.16.0 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.0.8 numba-0.60.0 pooch-1.8.2 pycparser-2.22 soundfile-0.12.1 soxr-0.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/294.9 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 153.6/294.9 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.9/294.9 kB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is Loaded\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "for dirname, _, filenames in os.walk('C:/Users/Shweta/OneDrive/Desktop/Speech Emotional'):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        label = filename.split('_')[-1]\n",
    "        label = label.split('.')[0]\n",
    "        labels.append(label.lower())\n",
    "    if len(paths) == 2800:\n",
    "         break\n",
    "print('Dataset is Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7442"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Shweta/OneDrive/Desktop/Speech Emotional\\\\1001_DFA_DIS_DISGUST.wav',\n",
       " 'C:/Users/Shweta/OneDrive/Desktop/Speech Emotional\\\\1001_DFA_FEA_FEAR.wav',\n",
       " 'C:/Users/Shweta/OneDrive/Desktop/Speech Emotional\\\\1001_DFA_HAP_HAPPY.wav',\n",
       " 'C:/Users/Shweta/OneDrive/Desktop/Speech Emotional\\\\1001_DFA_NEU_NEUTRAL.wav',\n",
       " 'C:/Users/Shweta/OneDrive/Desktop/Speech Emotional\\\\1001_DFA_SAD_SAD.wav']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disgust', 'fear', 'happy', 'neutral', 'sad']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech    label\n",
       "0  C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...  disgust\n",
       "1  C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...     fear\n",
       "2  C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...    happy\n",
       "3  C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...  neutral\n",
       "4  C:/Users/Shweta/OneDrive/Desktop/Speech Emotio...      sad"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "xx             5073\n",
       "hi              364\n",
       "lo              364\n",
       "md              364\n",
       "disgust           1\n",
       "               ... \n",
       "anger (231)       1\n",
       "anger (230)       1\n",
       "anger (23)        1\n",
       "anger (229)       1\n",
       "anger (999)       1\n",
       "Name: count, Length: 1281, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.4.7-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shweta\\appdata\\roaming\\python\\python312\\site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Downloading sounddevice-0.4.7-py3-none-win_amd64.whl (200 kB)\n",
      "   ---------------------------------------- 0.0/200.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/200.1 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 61.4/200.1 kB 656.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 194.6/200.1 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 200.1/200.1 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.4.7\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved as test_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf \n",
    "\n",
    "def record_audio(filename, duration=5, fs=44100):\n",
    "    print(\"Recording...\")\n",
    "    myrecording = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    sf.write(filename, myrecording, fs)\n",
    "    print(\"Recording saved as\", filename)\n",
    "\n",
    "record_audio('test_audio.wav') #recording and uploading audio files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/Shweta/OneDrive/Desktop/Speech Emotional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(file_path):\n",
    "    y, sr = librosa.load(file_path, duration=5.0)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "features = extract_audio_features('C:/Users/Shweta/OneDrive/Desktop/Speech Emotional/1001_IEO_FEA_HI.wav')\n",
    "print(features.shape)#preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shweta\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5865 - loss: 0.6981\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6905 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5863 - loss: 0.6752 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6867 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5202 - loss: 0.6777 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4828 - loss: 0.7363 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5615 - loss: 0.6971 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4673 - loss: 0.7130 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5270 - loss: 0.7291 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.6608 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "#training the models\n",
    "audio_features = np.random.rand(100, 13)  # 100 samples, 13 features each\n",
    "audio_labels = np.random.randint(0, 2, 100)  # 100 labels (0 or 1)\n",
    "\n",
    "audio_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(13,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # Assuming 2 classes: happy and sad\n",
    "])\n",
    "audio_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "audio_model.fit(audio_features, audio_labels, epochs=10)\n",
    "\n",
    "# Save model\n",
    "audio_model.save('audio_emotion_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_female_voice(file_path):\n",
    "    \n",
    "    return True  # Assuming all voices are female for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_language(file_path):\n",
    "   \n",
    "    return True  # Assume all voices are in English for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Sad\n"
     ]
    }
   ],
   "source": [
    "def predict_emotion_from_audio(file_path):\n",
    "    if not is_female_voice(file_path):\n",
    "        print(\"Please upload a female voice.\")\n",
    "        return\n",
    "    if not is_english_language(file_path):\n",
    "        print(\"Please upload an English voice.\")\n",
    "        return\n",
    "    \n",
    "    features = extract_audio_features(file_path)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    audio_model = tf.keras.models.load_model('audio_emotion_model.h5')\n",
    "    prediction = audio_model.predict(features)\n",
    "    emotion = np.argmax(prediction)\n",
    "    if emotion == 0:\n",
    "        print(\"Sad\")\n",
    "    else:\n",
    "        print(\"Happy\")\n",
    "\n",
    "predict_emotion_from_audio('C:/Users/Shweta/OneDrive/Desktop/Speech Emotional/1001_DFA_SAD_SAD.wav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
